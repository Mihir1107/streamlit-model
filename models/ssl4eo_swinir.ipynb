{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% SSL4EO + SwinIR-style SR with physics-based loss\n",
    "import os, math, logging, tarfile, random\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import Resampling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------\n",
    "# Directories & constants\n",
    "# -----------------------\n",
    "SSL4EO_DIR   = \"data_ssl4eo\"\n",
    "SCENES_ROOT  = os.path.join(SSL4EO_DIR, \"scenes\")   # recursive search for all_bands.tif\n",
    "MODELS_DIR   = \"models\"\n",
    "\n",
    "# Hooks for future pretraining (ECOSTRESS / HLS) – NOT used here, just kept open\n",
    "ECOSTRESS_DIR    = \"data_ecostress\"\n",
    "PROCESSED_DIR    = \"data_processed\"\n",
    "RAW_DIR          = \"data_raw\"\n",
    "ECO_BEST         = os.path.join(MODELS_DIR, \"ecostress_pretrained_best.pth\")\n",
    "ECO_LAST         = os.path.join(MODELS_DIR, \"ecostress_pretrained_last.pth\")\n",
    "\n",
    "os.makedirs(SSL4EO_DIR,  exist_ok=True)\n",
    "os.makedirs(SCENES_ROOT, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR,  exist_ok=True)\n",
    "\n",
    "# Training / patch config\n",
    "UPSCALE        = 2         # 2× SR here; can change to 4 with HR/LR logic consistent\n",
    "HR_PATCH       = 128       # HR patch size\n",
    "LR_PATCH       = HR_PATCH // UPSCALE\n",
    "BATCH_SIZE     = 4\n",
    "NUM_EPOCHS     = 50\n",
    "LEARNING_RATE  = 1e-4\n",
    "PHYS_LAMBDA    = 0.1       # weight for physics-based LR consistency loss\n",
    "\n",
    "# Patches per scene per epoch\n",
    "PATCHES_PER_SCENE_TRAIN = 4\n",
    "PATCHES_PER_SCENE_VAL   = 2\n",
    "PATCHES_PER_SCENE_TEST  = 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s:%(name)s: %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(\"infranova_ssl4eo_swinir\")\n",
    "\n",
    "# SSL4EO archive URL (same as before)\n",
    "SSL4EO_URL = (\n",
    "    \"https://huggingface.co/datasets/torchgeo/ssl4eo_l_benchmark/resolve/main/\"\n",
    "    \"ssl4eo_l_oli_tirs_toa_benchmark.tar.gz?download=true\"\n",
    ")\n",
    "\n",
    "# We only use these bands from all_bands.tif\n",
    "BAND_IDX = {\n",
    "    \"B2\": 2,    # Blue\n",
    "    \"B3\": 3,    # Green\n",
    "    \"B4\": 4,    # Red\n",
    "    \"B10\": 10,  # Thermal IR 1\n",
    "    \"B11\": 11   # Thermal IR 2\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# Utils: normalization & metrics\n",
    "# -----------------------\n",
    "def norm_np(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Per-band min-max normalization to [0,1] with NaN/Inf protection.\n",
    "    \"\"\"\n",
    "    a = np.array(a, dtype=np.float32)\n",
    "    if np.isnan(a).any() or np.isinf(a).any():\n",
    "        a = np.nan_to_num(a, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    mn = float(np.nanmin(a))\n",
    "    mx = float(np.nanmax(a))\n",
    "    if mx - mn < 1e-6:\n",
    "        return np.zeros_like(a, dtype=np.float32)\n",
    "    return ((a - mn) / (mx - mn)).astype(np.float32)\n",
    "\n",
    "\n",
    "def compute_metrics(pred: np.ndarray, target: np.ndarray):\n",
    "    \"\"\"\n",
    "    PSNR / SSIM / RMSE on [0,1] normalized arrays.\n",
    "    In SIH terms, RMSE can be interpreted as normalized Kelvin error if we map\n",
    "    back to physical K range later.\n",
    "    \"\"\"\n",
    "    pred   = np.nan_to_num(pred,   nan=0.0, posinf=1.0, neginf=0.0)\n",
    "    target = np.nan_to_num(target, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "    mse = float(np.mean((pred - target) ** 2))\n",
    "    if not np.isfinite(mse) or mse < 1e-12:\n",
    "        psnr_val = 100.0\n",
    "        rmse_val = 0.0\n",
    "    else:\n",
    "        psnr_val = 10 * math.log10(1.0 / mse)\n",
    "        rmse_val = math.sqrt(mse)\n",
    "    try:\n",
    "        ssim_val = ssim(target, pred, data_range=1.0)\n",
    "    except Exception:\n",
    "        ssim_val = 0.0\n",
    "    return psnr_val, ssim_val, rmse_val\n",
    "\n",
    "# -----------------------\n",
    "# SSL4EO discovery / download\n",
    "# -----------------------\n",
    "def discover_ssl4eo_scenes(root=SCENES_ROOT):\n",
    "    \"\"\"\n",
    "    Recursively find all scenes that contain `all_bands.tif`.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(root, \"**\", \"all_bands.tif\")\n",
    "    scene_files = sorted(glob(pattern, recursive=True))\n",
    "    logger.info(f\"Discovered {len(scene_files)} SSL4EO scenes with all_bands.tif\")\n",
    "    return scene_files\n",
    "\n",
    "\n",
    "def maybe_download_ssl4eo(archive_dir=SSL4EO_DIR, scenes_root=SCENES_ROOT):\n",
    "    \"\"\"\n",
    "    If no scenes found, download the SSL4EO benchmark archive and extract.\n",
    "    If already present, return quickly.\n",
    "    \"\"\"\n",
    "    scenes = discover_ssl4eo_scenes(scenes_root)\n",
    "    if len(scenes) > 0:\n",
    "        return scenes\n",
    "\n",
    "    logger.info(\"No SSL4EO scenes found. Attempting to download archive...\")\n",
    "    os.makedirs(archive_dir, exist_ok=True)\n",
    "    archive_path = os.path.join(archive_dir, \"ssl4eo_benchmark.tar.gz\")\n",
    "\n",
    "    if not os.path.exists(archive_path):\n",
    "        import requests\n",
    "        with requests.get(SSL4EO_URL, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            total = int(r.headers.get(\"content-length\", 0))\n",
    "            logger.info(f\"Downloading SSL4EO archive ({total/1e9:.2f} GB approx)...\")\n",
    "            with open(archive_path, \"wb\") as f, tqdm(\n",
    "                total=total, unit=\"B\", unit_scale=True, desc=\"ssl4eo_download\"\n",
    "            ) as pbar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "    else:\n",
    "        logger.info(f\"Found existing archive: {archive_path}\")\n",
    "\n",
    "    logger.info(f\"Extracting {archive_path} -> {scenes_root}\")\n",
    "    os.makedirs(scenes_root, exist_ok=True)\n",
    "    with tarfile.open(archive_path, \"r:gz\") as tf:\n",
    "        tf.extractall(path=scenes_root)\n",
    "    logger.info(\"Extraction finished.\")\n",
    "    return discover_ssl4eo_scenes(scenes_root)\n",
    "\n",
    "# -----------------------\n",
    "# Dataset: SSL4EOPatchDataset\n",
    "# -----------------------\n",
    "class SSL4EOPatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    For each scene:\n",
    "      - Loads all_bands.tif\n",
    "      - Uses B2/B3/B4 as HR optical guidance (3 channels)\n",
    "      - Uses either B10 or B11 (chosen randomly) as HR thermal \"truth\"\n",
    "      - Synthesizes LR thermal by downsampling HR thermal with factor UPSCALE\n",
    "      - Returns aligned patches:\n",
    "            lr_thermal (1, LR, LR),\n",
    "            hr_rgb     (3, HR, HR),\n",
    "            hr_thermal (1, HR, HR)\n",
    "    Each scene contributes `patches_per_scene` random patches per epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, scene_files, hr_patch=HR_PATCH, upscale=UPSCALE,\n",
    "                 patches_per_scene=4, mode=\"train\"):\n",
    "        super().__init__()\n",
    "        self.scene_files = list(scene_files)\n",
    "        self.hr_patch = hr_patch\n",
    "        self.lr_patch = hr_patch // upscale\n",
    "        self.upscale = upscale\n",
    "        self.patches_per_scene = patches_per_scene\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        # Each scene contributes 'patches_per_scene' patches per epoch\n",
    "        return len(self.scene_files) * self.patches_per_scene\n",
    "\n",
    "    def _read_bands(self, scene_path):\n",
    "        with rasterio.open(scene_path) as src:\n",
    "            # We read only 5 bands: B2,B3,B4,B10,B11\n",
    "            bands = src.read([\n",
    "                BAND_IDX[\"B2\"], BAND_IDX[\"B3\"], BAND_IDX[\"B4\"],\n",
    "                BAND_IDX[\"B10\"], BAND_IDX[\"B11\"]\n",
    "            ]).astype(np.float32)  # shape: (5, H, W)\n",
    "        return bands\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Map global index to scene index\n",
    "        scene_idx = idx // self.patches_per_scene\n",
    "        scene_path = self.scene_files[scene_idx]\n",
    "\n",
    "        bands = self._read_bands(scene_path)    # (5, H, W)\n",
    "        rgb = bands[0:3, :, :]                  # (3, H, W)  -> B2,B3,B4\n",
    "        t10 = bands[3, :, :]                    # (H, W)\n",
    "        t11 = bands[4, :, :]                    # (H, W)\n",
    "\n",
    "        # Randomly choose B10 or B11 as HR thermal target\n",
    "        if random.random() < 0.5:\n",
    "            thermal_hr = t10\n",
    "        else:\n",
    "            thermal_hr = t11\n",
    "\n",
    "        # Normalize optical and thermal\n",
    "        rgb_n = np.stack([norm_np(rgb[c]) for c in range(3)], axis=0)  # (3,H,W)\n",
    "        thr_n = norm_np(thermal_hr)                                    # (H,W)\n",
    "\n",
    "        H, W = thr_n.shape\n",
    "\n",
    "        # Pad small scenes if needed\n",
    "        if H < self.hr_patch or W < self.hr_patch:\n",
    "            pad_y = max(0, self.hr_patch - H)\n",
    "            pad_x = max(0, self.hr_patch - W)\n",
    "            thr_n = np.pad(thr_n, ((0, pad_y), (0, pad_x)), mode='reflect')\n",
    "            rgb_n = np.pad(rgb_n, ((0, 0), (0, pad_y), (0, pad_x)), mode='reflect')\n",
    "            H, W = thr_n.shape\n",
    "\n",
    "        # Synthesize LR thermal by downsampling HR thermal\n",
    "        H_lr, W_lr = H // self.upscale, W // self.upscale\n",
    "        lr_full = F.interpolate(\n",
    "            torch.from_numpy(thr_n).unsqueeze(0).unsqueeze(0).float(),  # (1,1,H,W)\n",
    "            size=(H_lr, W_lr),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        ).squeeze().numpy()  # (H_lr, W_lr)\n",
    "\n",
    "        # Random HR crop\n",
    "        max_y = H - self.hr_patch\n",
    "        max_x = W - self.hr_patch\n",
    "        if max_y <= 0 or max_x <= 0:\n",
    "            y = 0\n",
    "            x = 0\n",
    "        else:\n",
    "            y = np.random.randint(0, max_y + 1)\n",
    "            x = np.random.randint(0, max_x + 1)\n",
    "\n",
    "        # HR crops\n",
    "        hr_t_patch   = thr_n[y:y + self.hr_patch, x:x + self.hr_patch]          # (HR, HR)\n",
    "        hr_rgb_patch = rgb_n[:, y:y + self.hr_patch, x:x + self.hr_patch]       # (3,HR,HR)\n",
    "\n",
    "        # LR aligned crop\n",
    "        ly, lx = y // self.upscale, x // self.upscale\n",
    "        lr_t_patch = lr_full[ly:ly + self.lr_patch, lx:lx + self.lr_patch]      # (LR, LR)\n",
    "\n",
    "        # Safety cropping to ensure exact sizes\n",
    "        if hr_t_patch.shape != (self.hr_patch, self.hr_patch):\n",
    "            hr_t_patch   = hr_t_patch[:self.hr_patch, :self.hr_patch]\n",
    "            hr_rgb_patch = hr_rgb_patch[:, :self.hr_patch, :self.hr_patch]\n",
    "        if lr_t_patch.shape != (self.lr_patch, self.lr_patch):\n",
    "            lr_t_patch = lr_t_patch[:self.lr_patch, :self.lr_patch]\n",
    "\n",
    "        # To tensors\n",
    "        lr_t   = torch.from_numpy(lr_t_patch).unsqueeze(0).float()  # (1, LR, LR)\n",
    "        hr_rgb = torch.from_numpy(hr_rgb_patch).float()             # (3, HR, HR)\n",
    "        hr_t   = torch.from_numpy(hr_t_patch).unsqueeze(0).float()  # (1, HR, HR)\n",
    "\n",
    "        return lr_t, hr_rgb, hr_t\n",
    "\n",
    "# -----------------------\n",
    "# SwinIR-style model (simplified)\n",
    "# -----------------------\n",
    "# This is a lightweight, SwinIR-inspired architecture:\n",
    "#  - early fusion of upsampled LR thermal + HR RGB  -> 4 channels\n",
    "#  - patch-embedding conv\n",
    "#  - several \"Swin-style\" residual blocks using conv + windowed self-attention-ish\n",
    "#  - final conv to 1-channel HR thermal\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, in_channels=4, embed_dim=96, patch_size=1):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, padding=0)\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "class SimpleWindowAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Very simplified stand-in for Swin window attention:\n",
    "    - Flattens spatial dims -> sequence\n",
    "    - Applies MultiheadAttention globally (not true shifted-window Swin, but similar idea)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, H, W)\n",
    "        Flatten -> (B, H*W, C), apply attention, reshape back.\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        x_perm = x.view(B, C, H * W).permute(0, 2, 1)  # (B, N, C)\n",
    "        x_norm = self.norm(x_perm)\n",
    "        out, _ = self.attn(x_norm, x_norm, x_norm)     # (B, N, C)\n",
    "        out = out.permute(0, 2, 1).view(B, C, H, W)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SwinIRBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    SwinIR-style residual block:\n",
    "      - window/global attention\n",
    "      - MLP (Conv-based)\n",
    "      - residual connections\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, mlp_ratio=2.0, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.attn = SimpleWindowAttention(dim, num_heads=num_heads)\n",
    "\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(dim, hidden_dim, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(hidden_dim, dim, kernel_size=1),\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Norm over channels for attention path\n",
    "        x_perm = x.view(B, C, H * W).permute(0, 2, 1)  # (B,N,C)\n",
    "        x_norm = self.norm1(x_perm).permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Attention residual\n",
    "        attn_out = self.attn(x_norm)\n",
    "        x = x + attn_out\n",
    "\n",
    "        # Norm for MLP path\n",
    "        x_perm2 = x.view(B, C, H * W).permute(0, 2, 1)\n",
    "        x_norm2 = self.norm2(x_perm2).permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # MLP residual\n",
    "        mlp_out = self.mlp(x_norm2)\n",
    "        x = x + mlp_out\n",
    "        return x\n",
    "\n",
    "\n",
    "class SwinIRFusionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    SSL4EO thermal SR with SwinIR-style backbone.\n",
    "    Inputs:\n",
    "      - xT_lr: (B,1,LR,LR)    low-res thermal\n",
    "      - xO_hr: (B,3,HR,HR)    high-res optical (RGB)\n",
    "    Steps:\n",
    "      1. Upsample xT_lr to HR\n",
    "      2. Concatenate with RGB -> (B,4,HR,HR)\n",
    "      3. Patch embedding conv -> feature maps\n",
    "      4. Several SwinIRBlocks\n",
    "      5. Final conv -> 1-channel HR thermal\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=96, num_blocks=6, upscale=UPSCALE):\n",
    "        super().__init__()\n",
    "        self.upscale = upscale\n",
    "\n",
    "        # Early upsample for LR thermal to HR grid\n",
    "        self.thermal_upsample = nn.Upsample(scale_factor=upscale, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # 4-channel fusion input (1 thermal + 3 RGB)\n",
    "        self.patch_embed = PatchEmbed(in_channels=4, embed_dim=embed_dim, patch_size=1)\n",
    "\n",
    "        # SwinIR-style blocks\n",
    "        blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(SwinIRBlock(dim=embed_dim, mlp_ratio=2.0, num_heads=4))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "        # Simple refinement\n",
    "        self.refine = nn.Sequential(\n",
    "            nn.Conv2d(embed_dim, embed_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(embed_dim, embed_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Output head: 1-channel HR thermal\n",
    "        self.conv_out = nn.Conv2d(embed_dim, 1, kernel_size=3, padding=1)\n",
    "\n",
    "        # Init\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, a=0, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, xT_lr, xO_hr):\n",
    "        # xT_lr: (B,1,LR,LR)\n",
    "        # xO_hr: (B,3,HR,HR)\n",
    "        # 1) Upsample LR thermal to HR\n",
    "        xT_up = self.thermal_upsample(xT_lr)  # (B,1,HR,HR)\n",
    "\n",
    "        # 2) Concatenate channels\n",
    "        x_in = torch.cat([xT_up, xO_hr], dim=1)  # (B,4,HR,HR)\n",
    "\n",
    "        # 3) Patch embedding\n",
    "        feat = self.patch_embed(x_in)           # (B,embed_dim,HR,HR)\n",
    "\n",
    "        # 4) SwinIR blocks\n",
    "        feat = self.blocks(feat)\n",
    "\n",
    "        # 5) Refinement + output\n",
    "        feat = self.refine(feat)\n",
    "        out  = self.conv_out(feat)              # (B,1,HR,HR)\n",
    "        return out\n",
    "\n",
    "# -----------------------\n",
    "# Training with physics-based loss + resume\n",
    "# -----------------------\n",
    "def train_ssl4eo_swinir(num_epochs=NUM_EPOCHS):\n",
    "    # 1) Find / download scenes\n",
    "    scenes = discover_ssl4eo_scenes()\n",
    "    if len(scenes) == 0:\n",
    "        scenes = maybe_download_ssl4eo()\n",
    "    if len(scenes) == 0:\n",
    "        logger.error(\"No SSL4EO scenes available; aborting.\")\n",
    "        return\n",
    "\n",
    "    # 2) Train/val/test split\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    scenes_shuffled = scenes.copy()\n",
    "    random.shuffle(scenes_shuffled)\n",
    "\n",
    "    n_total = len(scenes_shuffled)\n",
    "    n_train = int(0.7 * n_total)\n",
    "    n_val   = int(0.15 * n_total)\n",
    "    n_test  = n_total - n_train - n_val\n",
    "\n",
    "    train_scenes = scenes_shuffled[:n_train]\n",
    "    val_scenes   = scenes_shuffled[n_train:n_train + n_val]\n",
    "    test_scenes  = scenes_shuffled[n_train + n_val:]\n",
    "\n",
    "    logger.info(\n",
    "        \"Starting SSL4EO SwinIR training with physics-aware loss.\\n\"\n",
    "        f\"Scene split -> Train: {len(train_scenes)}, Val: {len(val_scenes)}, Test: {len(test_scenes)}\"\n",
    "    )\n",
    "\n",
    "    # 3) Datasets / loaders\n",
    "    train_ds = SSL4EOPatchDataset(\n",
    "        train_scenes, hr_patch=HR_PATCH, upscale=UPSCALE,\n",
    "        patches_per_scene=PATCHES_PER_SCENE_TRAIN, mode=\"train\"\n",
    "    )\n",
    "    val_ds = SSL4EOPatchDataset(\n",
    "        val_scenes, hr_patch=HR_PATCH, upscale=UPSCALE,\n",
    "        patches_per_scene=PATCHES_PER_SCENE_VAL, mode=\"val\"\n",
    "    )\n",
    "    test_ds = SSL4EOPatchDataset(\n",
    "        test_scenes, hr_patch=HR_PATCH, upscale=UPSCALE,\n",
    "        patches_per_scene=PATCHES_PER_SCENE_TEST, mode=\"test\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=0, pin_memory=(DEVICE.type == \"cuda\")\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=(DEVICE.type == \"cuda\")\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=(DEVICE.type == \"cuda\")\n",
    "    )\n",
    "\n",
    "    # 4) Model, optimizer, loss\n",
    "    model = SwinIRFusionNet(embed_dim=96, num_blocks=6, upscale=UPSCALE).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    mse_loss  = nn.MSELoss()\n",
    "\n",
    "    BEST_PATH = os.path.join(MODELS_DIR, \"ssl4eo_best_swinir.pth\")\n",
    "    LAST_PATH = os.path.join(MODELS_DIR, \"ssl4eo_last_swinir.pth\")\n",
    "\n",
    "    best_val_psnr = -1e9\n",
    "    start_epoch = 1\n",
    "\n",
    "    # Resume training if LAST_PATH exists\n",
    "    if os.path.exists(LAST_PATH):\n",
    "        try:\n",
    "            ckpt = torch.load(LAST_PATH, map_location=DEVICE)\n",
    "            model.load_state_dict(ckpt[\"model_state\"])\n",
    "            optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "            start_epoch = ckpt[\"epoch\"] + 1\n",
    "            best_val_psnr = ckpt.get(\"best_val_psnr\", -1e9)\n",
    "            logger.info(\n",
    "                f\"Resuming from checkpoint {LAST_PATH}: \"\n",
    "                f\"start_epoch={start_epoch}, best_val_psnr={best_val_psnr:.3f}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to load checkpoint {LAST_PATH}: {e}\")\n",
    "            start_epoch = 1\n",
    "    else:\n",
    "        logger.info(\"No previous SwinIR checkpoint found; starting at epoch 1.\")\n",
    "\n",
    "    logger.info(f\"Training epochs: {start_epoch} -> {num_epochs}\")\n",
    "\n",
    "    # 5) Training loop\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        it = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} (train)\")\n",
    "        for lr_t, hr_rgb, hr_t in pbar:\n",
    "            lr_t   = lr_t.to(DEVICE)      # (B,1,LR,LR)\n",
    "            hr_rgb = hr_rgb.to(DEVICE)    # (B,3,HR,HR)\n",
    "            hr_t   = hr_t.to(DEVICE)      # (B,1,HR,HR)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_hr = model(lr_t, hr_rgb)  # (B,1,HR,HR)\n",
    "\n",
    "            # Data fidelity loss at HR\n",
    "            loss_fid = mse_loss(pred_hr, hr_t)\n",
    "\n",
    "            # Physics-aware loss:\n",
    "            # Downsample predicted HR to LR and match the input LR thermal\n",
    "            pred_lr = F.interpolate(\n",
    "                pred_hr, size=(lr_t.shape[2], lr_t.shape[3]),\n",
    "                mode=\"area\"  # average-style downsampling\n",
    "            )\n",
    "            loss_phys = mse_loss(pred_lr, lr_t)\n",
    "\n",
    "            loss = loss_fid + PHYS_LAMBDA * loss_phys\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            running += float(loss.item())\n",
    "            it += 1\n",
    "            pbar.set_postfix(loss=running / max(1, it))\n",
    "\n",
    "        avg_train_loss = running / max(1, it)\n",
    "        logger.info(f\"Epoch {epoch} TRAIN loss={avg_train_loss:.6f}\")\n",
    "\n",
    "        # 6) Validation\n",
    "        model.eval()\n",
    "        ps_sum = ss_sum = rm_sum = 0.0\n",
    "        cnt = 0\n",
    "        with torch.no_grad():\n",
    "            for lr_t, hr_rgb, hr_t in tqdm(val_loader, desc=f\"Epoch {epoch} (val)\"):\n",
    "                lr_t   = lr_t.to(DEVICE)\n",
    "                hr_rgb = hr_rgb.to(DEVICE)\n",
    "                hr_t   = hr_t.to(DEVICE)\n",
    "\n",
    "                out = model(lr_t, hr_rgb)\n",
    "                pred = out.cpu().squeeze().numpy()\n",
    "                tgt  = hr_t.cpu().squeeze().numpy()\n",
    "\n",
    "                ps, ss, rm = compute_metrics(pred, tgt)\n",
    "                ps_sum += ps\n",
    "                ss_sum += ss\n",
    "                rm_sum += rm\n",
    "                cnt += 1\n",
    "\n",
    "        if cnt > 0:\n",
    "            avg_ps = ps_sum / cnt\n",
    "            avg_ss = ss_sum / cnt\n",
    "            avg_rm = rm_sum / cnt\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} VAL (SwinIR) PSNR={avg_ps:.3f} dB, \"\n",
    "                f\"SSIM={avg_ss:.4f}, RMSE={avg_rm:.6f}\"\n",
    "            )\n",
    "            if avg_ps > best_val_psnr:\n",
    "                best_val_psnr = avg_ps\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model_state\": model.state_dict(),\n",
    "                        \"epoch\": epoch,\n",
    "                        \"best_val_psnr\": best_val_psnr,\n",
    "                    },\n",
    "                    BEST_PATH,\n",
    "                )\n",
    "                logger.info(f\"Saved BEST SwinIR model -> {BEST_PATH} (PSNR={avg_ps:.3f})\")\n",
    "\n",
    "        # Always save LAST\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                \"best_val_psnr\": best_val_psnr,\n",
    "            },\n",
    "            LAST_PATH,\n",
    "        )\n",
    "        logger.info(f\"Saved LAST SwinIR model -> {LAST_PATH} (epoch={epoch})\")\n",
    "\n",
    "    # 7) Final TEST evaluation with best model\n",
    "    if os.path.exists(BEST_PATH):\n",
    "        ckpt = torch.load(BEST_PATH, map_location=DEVICE)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        logger.info(f\"Loaded BEST SwinIR model from {BEST_PATH} for TEST evaluation.\")\n",
    "\n",
    "    model.eval()\n",
    "    ps_sum = ss_sum = rm_sum = 0.0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for lr_t, hr_rgb, hr_t in tqdm(test_loader, desc=\"TEST (SwinIR)\"):\n",
    "            lr_t   = lr_t.to(DEVICE)\n",
    "            hr_rgb = hr_rgb.to(DEVICE)\n",
    "            hr_t   = hr_t.to(DEVICE)\n",
    "\n",
    "            out = model(lr_t, hr_rgb)\n",
    "            pred = out.cpu().squeeze().numpy()\n",
    "            tgt  = hr_t.cpu().squeeze().numpy()\n",
    "\n",
    "            ps, ss, rm = compute_metrics(pred, tgt)\n",
    "            ps_sum += ps\n",
    "            ss_sum += ss\n",
    "            rm_sum += rm\n",
    "            cnt += 1\n",
    "\n",
    "    if cnt > 0:\n",
    "        avg_ps = ps_sum / cnt\n",
    "        avg_ss = ss_sum / cnt\n",
    "        avg_rm = rm_sum / cnt\n",
    "        logger.info(\n",
    "            f\"TEST SUMMARY (SSL4EO + SwinIR-style, RGB-guided, physics-aware): \"\n",
    "            f\"PSNR={avg_ps:.3f} dB, SSIM={avg_ss:.4f}, RMSE={avg_rm:.6f}\"\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "# %% Script entry\n",
    "if __name__ == \"__main__\":\n",
    "    train_ssl4eo_swinir()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
